{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ[\"JAX_ENABLE_X64\"] = \"True\"\n",
    "\n",
    "import lagrangebench\n",
    "import haiku as hk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a 2D dataset called HT.\n",
      "Train snapshot have shape (950, 12, 2) (n_nodes, seq_len, xy pos).\n",
      "Val snapshot have shape (950, 26, 2) (n_nodes, rollout, xy pos).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ht2d_train = lagrangebench.data.HT2D(\"train\", extra_seq_length=5)  # extra_seq_length=5 will be clear later\n",
    "ht2d_valid = lagrangebench.data.HT2D(\"valid\", extra_seq_length=20)\n",
    "\n",
    "print(\n",
    "    f\"This is a {ht2d_train.metadata['dim']}D dataset \"\n",
    "    f\"called {ht2d_train.metadata['case']}.\\n\"\n",
    "    f\"Train snapshot have shape {ht2d_train[0][0].shape} (n_nodes, seq_len, xy pos).\\n\"\n",
    "    f\"Val snapshot have shape {ht2d_valid[0][0].shape} (n_nodes, rollout, xy pos).\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht2d_train[439][1][0:864]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gns(x):\n",
    "    return lagrangebench.GNS(\n",
    "        particle_dimension=ht2d_train.metadata[\"dim\"],\n",
    "        latent_size=16,\n",
    "        blocks_per_step=2,\n",
    "        num_mp_steps=4,\n",
    "        particle_type_embedding_size=8,\n",
    "    )(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gns = hk.without_apply_rng(hk.transform_with_state(gns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_std = 3e-4\n",
    "\n",
    "pf_config = lagrangebench.PushforwardConfig(\n",
    "    steps=[-1, 500, 700],  # training steps to unlock the relative stage\n",
    "    unrolls=[0, 2, 5],  # number of unroll steps per stage\n",
    "    probs=[7, 2, 1],  # relative probabilities to unroll to the relative stage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Case setup functions.\"\"\"\n",
    "\n",
    "from typing import Callable, Dict, Optional, Tuple, Union\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import Array, jit, lax, vmap\n",
    "from jax_md import space\n",
    "from jax_md.dataclasses import dataclass, static_field\n",
    "from jax_md.partition import NeighborList, NeighborListFormat\n",
    "\n",
    "from lagrangebench.data.utils import get_dataset_stats\n",
    "from lagrangebench.defaults import defaults\n",
    "from lagrangebench.train.strats import add_gns_noise\n",
    "\n",
    "from lagrangebench.case_setup.features import FeatureDict, TargetDict, physical_feature_builder\n",
    "from lagrangebench.case_setup.partition import neighbor_list\n",
    "\n",
    "TrainCaseOut = Tuple[Array, FeatureDict, TargetDict, NeighborList]\n",
    "EvalCaseOut = Tuple[FeatureDict, NeighborList]\n",
    "SampleIn = Tuple[jnp.ndarray, jnp.ndarray]\n",
    "\n",
    "AllocateFn = Callable[[Array, SampleIn, float, int], TrainCaseOut]\n",
    "AllocateEvalFn = Callable[[SampleIn], EvalCaseOut]\n",
    "\n",
    "PreprocessFn = Callable[[Array, SampleIn, float, NeighborList, int], TrainCaseOut]\n",
    "PreprocessEvalFn = Callable[[SampleIn, NeighborList], EvalCaseOut]\n",
    "\n",
    "IntegrateFn = Callable[[jnp.ndarray, jnp.ndarray], jnp.ndarray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CaseSetupFn:\n",
    "    \"\"\"Dataclass that contains all functions required to setup the case and simulate.\n",
    "\n",
    "    Attributes:\n",
    "        allocate: AllocateFn, runs the preprocessing without having a NeighborList as\n",
    "            input.\n",
    "        preprocess: PreprocessFn, takes positions from the dataloader, computes\n",
    "            velocities, adds random-walk noise if needed, then updates the neighbor\n",
    "            list, and return the inputs to the neural network as well as the targets.\n",
    "        allocate_eval: AllocateEvalFn, same as allocate, but without noise addition\n",
    "            and without targets.\n",
    "        preprocess_eval: PreprocessEvalFn, same as allocate_eval, but jit-able.\n",
    "        integrate: IntegrateFn, semi-implicit Euler integrations step respecting\n",
    "            all boundary conditions.\n",
    "        displacement: space.DisplacementFn, displacement function aware of boundary\n",
    "            conditions (periodic on non-periodic).\n",
    "        normalization_stats: Dict, normalization statisticss for input velocities and\n",
    "            output acceleration.\n",
    "    \"\"\"\n",
    "\n",
    "    allocate: AllocateFn = static_field()\n",
    "    preprocess: PreprocessFn = static_field()\n",
    "    allocate_eval: AllocateEvalFn = static_field()\n",
    "    preprocess_eval: PreprocessEvalFn = static_field()\n",
    "    integrate: IntegrateFn = static_field()\n",
    "    displacement: space.DisplacementFn = static_field()\n",
    "    normalization_stats: Dict = static_field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_builder(\n",
    "    box: Tuple[float, float, float],\n",
    "    metadata: Dict,\n",
    "    input_seq_length: int,\n",
    "    isotropic_norm: bool = defaults.isotropic_norm,\n",
    "    noise_std: float = defaults.noise_std,\n",
    "    external_force_fn: Optional[Callable] = None,\n",
    "    magnitude_features: bool = defaults.magnitude_features,\n",
    "    neighbor_list_backend: str = defaults.neighbor_list_backend,\n",
    "    neighbor_list_multiplier: float = defaults.neighbor_list_multiplier,\n",
    "    dtype: jnp.dtype = defaults.dtype,\n",
    "):\n",
    "    \"\"\"Set up a CaseSetupFn that contains every required function besides the model.\n",
    "\n",
    "    Inspired by the `partition.neighbor_list` function in JAX-MD.\n",
    "\n",
    "    The core functions are:\n",
    "        * allocate, allocate memory for the neighbors list.\n",
    "        * preprocess, update the neighbors list.\n",
    "        * integrate, semi-implicit Euler respecting periodic boundary conditions.\n",
    "\n",
    "    Args:\n",
    "        box: Box xyz sizes of the system.\n",
    "        metadata: Dataset metadata dictionary.\n",
    "        input_seq_length: Length of the input sequence.\n",
    "        isotropic_norm: Whether to normalize dimensions equally.\n",
    "        noise_std: Noise standard deviation.\n",
    "        external_force_fn: External force function.\n",
    "        magnitude_features: Whether to add velocity magnitudes in the features.\n",
    "        neighbor_list_backend: Backend of the neighbor list.\n",
    "        neighbor_list_multiplier: Capacity multiplier of the neighbor list.\n",
    "        dtype: Data type.\n",
    "    \"\"\"\n",
    "    normalization_stats = get_dataset_stats(metadata, isotropic_norm, noise_std)\n",
    "\n",
    "    # apply PBC in all directions or not at all\n",
    "    if jnp.array(metadata[\"periodic_boundary_conditions\"]).any():\n",
    "        displacement_fn, shift_fn = space.periodic(side=jnp.array(box))\n",
    "        #displacement_fn(Ra, Rb, **kwargs): Computes displacements between pairs of particles. Ra and Rb should be ndarrays of shape [spatial_dim]. Returns an ndarray of shape [spatial_dim]. \n",
    "        #shift_fn(R, dR, **kwargs): Moves points at position R by an amount dR.\n",
    "    else:\n",
    "        displacement_fn, shift_fn = space.free()\n",
    "\n",
    "    displacement_fn_set = vmap(displacement_fn, in_axes=(0, 0))\n",
    "\n",
    "    neighbor_fn = neighbor_list(\n",
    "        displacement_fn,\n",
    "        jnp.array(box),\n",
    "        backend=neighbor_list_backend,\n",
    "        r_cutoff=metadata[\"default_connectivity_radius\"],\n",
    "        capacity_multiplier=neighbor_list_multiplier,\n",
    "        mask_self=False,\n",
    "        format=NeighborListFormat.Sparse,\n",
    "        num_particles_max=metadata[\"num_particles_max\"],\n",
    "        pbc=metadata[\"periodic_boundary_conditions\"],\n",
    "    )\n",
    "\n",
    "    feature_transform = physical_feature_builder(\n",
    "        bounds=metadata[\"bounds\"],\n",
    "        normalization_stats=normalization_stats,\n",
    "        connectivity_radius=metadata[\"default_connectivity_radius\"],\n",
    "        displacement_fn=displacement_fn,\n",
    "        pbc=metadata[\"periodic_boundary_conditions\"],\n",
    "        magnitude_features=magnitude_features,\n",
    "        external_force_fn=external_force_fn,\n",
    "    )\n",
    "\n",
    "    def _compute_target(pos_input: jnp.ndarray) -> TargetDict:\n",
    "        # displacement(r1, r2) = r1-r2  # without PBC\n",
    "\n",
    "        current_velocity = displacement_fn_set(pos_input[:, 1], pos_input[:, 0])\n",
    "        next_velocity = displacement_fn_set(pos_input[:, 2], pos_input[:, 1])\n",
    "        current_acceleration = next_velocity - current_velocity\n",
    "\n",
    "        acc_stats = normalization_stats[\"acceleration\"]\n",
    "        normalized_acceleration = (\n",
    "            current_acceleration - acc_stats[\"mean\"]\n",
    "        ) / acc_stats[\"std\"]\n",
    "\n",
    "        vel_stats = normalization_stats[\"velocity\"]\n",
    "        normalized_velocity = (next_velocity - vel_stats[\"mean\"]) / vel_stats[\"std\"]\n",
    "        return {\n",
    "            \"acc\": normalized_acceleration,\n",
    "            \"vel\": normalized_velocity,\n",
    "            \"pos\": pos_input[:, -1],\n",
    "        }\n",
    "\n",
    "    def _preprocess(\n",
    "        sample: Tuple[jnp.ndarray, jnp.ndarray],\n",
    "        neighbors: Optional[NeighborList] = None,\n",
    "        is_allocate: bool = False,\n",
    "        mode: str = \"train\",\n",
    "        **kwargs,  # key, noise_std, unroll_steps\n",
    "    ) -> Union[TrainCaseOut, EvalCaseOut]:\n",
    "        pos_input = jnp.asarray(sample[0], dtype=dtype)\n",
    "        particle_type = jnp.asarray(sample[1])\n",
    "\n",
    "        if mode == \"train\":\n",
    "            key, noise_std = kwargs[\"key\"], kwargs[\"noise_std\"]\n",
    "            unroll_steps = kwargs[\"unroll_steps\"]\n",
    "            if pos_input.shape[1] > 1:\n",
    "                key, pos_input = add_gns_noise(\n",
    "                    key, pos_input, particle_type, input_seq_length, noise_std, shift_fn\n",
    "                )\n",
    "\n",
    "        # allocate the neighbor list\n",
    "        most_recent_position = pos_input[:, input_seq_length - 1]\n",
    "        num_particles = (particle_type != -1).sum()\n",
    "        if is_allocate:\n",
    "            neighbors = neighbor_fn.allocate(\n",
    "                most_recent_position, num_particles=num_particles\n",
    "            )\n",
    "        else:\n",
    "            neighbors = neighbors.update(\n",
    "                most_recent_position, num_particles=num_particles\n",
    "            )\n",
    "\n",
    "        # selected features\n",
    "        features = feature_transform(pos_input[:, :input_seq_length], neighbors)\n",
    "\n",
    "        if mode == \"train\":\n",
    "            # compute target acceleration. Inverse of postprocessing step.\n",
    "            # the \"-2\" is needed because we need the most recent position and one before\n",
    "            slice_begin = (0, input_seq_length - 2 + unroll_steps, 0)\n",
    "            slice_size = (pos_input.shape[0], 3, pos_input.shape[2])\n",
    "\n",
    "            target_dict = _compute_target(\n",
    "                lax.dynamic_slice(pos_input, slice_begin, slice_size)\n",
    "            )\n",
    "            return key, features, target_dict, neighbors\n",
    "        if mode == \"eval\":\n",
    "            return features, neighbors\n",
    "\n",
    "    def allocate_fn(key, sample, noise_std=0.0, unroll_steps=0):\n",
    "        return _preprocess(\n",
    "            sample,\n",
    "            key=key,\n",
    "            noise_std=noise_std,\n",
    "            unroll_steps=unroll_steps,\n",
    "            is_allocate=True,\n",
    "        )\n",
    "\n",
    "    @jit\n",
    "    def preprocess_fn(key, sample, noise_std, neighbors, unroll_steps=0):\n",
    "        return _preprocess(\n",
    "            sample, neighbors, key=key, noise_std=noise_std, unroll_steps=unroll_steps\n",
    "        )\n",
    "\n",
    "    def allocate_eval_fn(sample):\n",
    "        return _preprocess(sample, is_allocate=True, mode=\"eval\")\n",
    "\n",
    "    @jit\n",
    "    def preprocess_eval_fn(sample, neighbors):\n",
    "        return _preprocess(sample, neighbors, mode=\"eval\")\n",
    "\n",
    "    @jit\n",
    "    def integrate_fn(normalized_in, position_sequence):\n",
    "        \"\"\"Euler integrator to get position shift.\"\"\"\n",
    "        assert any([key in normalized_in for key in [\"pos\", \"vel\", \"acc\"]])\n",
    "\n",
    "        if \"pos\" in normalized_in:\n",
    "            # Zeroth euler step\n",
    "            return normalized_in[\"pos\"]\n",
    "        else:\n",
    "            most_recent_position = position_sequence[:, -1]\n",
    "            if \"vel\" in normalized_in:\n",
    "                # invert normalization\n",
    "                velocity_stats = normalization_stats[\"velocity\"]\n",
    "                new_velocity = velocity_stats[\"mean\"] + (\n",
    "                    normalized_in[\"vel\"] * velocity_stats[\"std\"]\n",
    "                )\n",
    "            elif \"acc\" in normalized_in:\n",
    "                # invert normalization.\n",
    "                acceleration_stats = normalization_stats[\"acceleration\"]\n",
    "                acceleration = acceleration_stats[\"mean\"] + (\n",
    "                    normalized_in[\"acc\"] * acceleration_stats[\"std\"]\n",
    "                )\n",
    "                # Second Euler step\n",
    "                most_recent_velocity = displacement_fn_set(\n",
    "                    most_recent_position, position_sequence[:, -2]\n",
    "                )\n",
    "                new_velocity = most_recent_velocity + acceleration  # * dt = 1\n",
    "\n",
    "            # First Euler step\n",
    "            return shift_fn(most_recent_position, new_velocity)\n",
    "\n",
    "    return CaseSetupFn(\n",
    "        allocate_fn,\n",
    "        preprocess_fn,\n",
    "        allocate_eval_fn,\n",
    "        preprocess_eval_fn,\n",
    "        integrate_fn,\n",
    "        displacement_fn,\n",
    "        normalization_stats,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 0.38])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = np.array([[0.0,1.0],[0.0,0.38]])\n",
    "#bounds = np.array(ht2d_train.metadata[\"bounds\"])\n",
    "box = bounds[:, 1] - bounds[:, 0]\n",
    "\n",
    "box\n",
    "#bounds[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function jax_md.space.periodic.<locals>.displacement_fn(Ra: jax.Array, Rb: jax.Array, perturbation: Optional[jax.Array] = None, **unused_kwargs) -> jax.Array>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displacement_fn, shift_fn = space.periodic(side=jnp.array(box))\n",
    "displacement_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacement_fn_set = vmap(displacement_fn, in_axes=(0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displacement: [ 0.2  -0.18]\n"
     ]
    }
   ],
   "source": [
    "Ra = jnp.array([0.3, 0.3])\n",
    "Rb = jnp.array([0.1, 0.1])\n",
    "displacement = displacement_fn(Ra, Rb)\n",
    "\n",
    "    # Get the shifted position vector\n",
    "#shifted_pos = shift_fn(Rb)\n",
    "    \n",
    "print(\"Displacement:\", displacement)\n",
    "#print(\"Shifted Position:\", shifted_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht2d_case = case_builder(\n",
    "    box=box,  # (x,y) array with the world size along each axis. (1.0, 1.0) for 2D TGV\n",
    "    metadata=ht2d_train.metadata,  # metadata dictionary\n",
    "    input_seq_length=6,  # number of consecutive time steps fed to the model\n",
    "    isotropic_norm=False,  # whether to normalize each dimension independently\n",
    "    noise_std=noise_std,  # noise standard deviation used by the random-walk noise\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CaseSetupFn(allocate=<function case_builder.<locals>.allocate_fn at 0x7f2b1b0151b0>, preprocess=<PjitFunction of <function case_builder.<locals>.preprocess_fn at 0x7f2b1b015240>>, allocate_eval=<function case_builder.<locals>.allocate_eval_fn at 0x7f2b1b015630>, preprocess_eval=<PjitFunction of <function case_builder.<locals>.preprocess_eval_fn at 0x7f2b1b0156c0>>, integrate=<PjitFunction of <function case_builder.<locals>.integrate_fn at 0x7f2b1b015ab0>>, displacement=<function periodic.<locals>.displacement_fn at 0x7f2b1b1b20e0>, normalization_stats={'acceleration': {'mean': Array([4.47690509e-05, 1.96038036e-05], dtype=float64), 'std': Array([0.00252051, 0.00134007], dtype=float64)}, 'velocity': {'mean': Array([ 3.21281608e-03, -2.85042406e-05], dtype=float64), 'std': Array([0.00373654, 0.00117393], dtype=float64)}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht2d_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uppili11/.local/lib/python3.10/site-packages/jax/_src/ops/scatter.py:94: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000, train/loss: 1.64200.\n",
      "010, train/loss: 0.49071.\n",
      "020, train/loss: 0.22857.\n",
      "030, train/loss: 0.13987.\n",
      "040, train/loss: 0.16064.\n",
      "050, train/loss: 0.45200.\n",
      "(eval) Reallocate neighbors list at step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uppili11/.local/lib/python3.10/site-packages/jax/_src/ops/scatter.py:94: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(eval) From (2, 8098) to (2, 8258)\n",
      "(eval) Reallocate neighbors list at step 6\n",
      "(eval) From (2, 8258) to (2, 8623)\n",
      "(eval) Reallocate neighbors list at step 13\n",
      "(eval) From (2, 8623) to (2, 9131)\n",
      "{'val/loss': 0.0008332215030598735, 'val/mse1': 1.538714813370024e-05, 'val/mse10': 0.0003000804581765784, 'val/mse5': 0.00014142839415986165, 'val/stdloss': 0.0, 'val/stdmse1': 0.0, 'val/stdmse10': 0.0, 'val/stdmse5': 0.0}\n",
      "060, train/loss: 0.20161.\n",
      "070, train/loss: 0.45718.\n",
      "080, train/loss: 0.11952.\n",
      "090, train/loss: 1.35452.\n",
      "100, train/loss: 0.07526.\n",
      "(eval) Reallocate neighbors list at step 1\n",
      "(eval) From (2, 8098) to (2, 8233)\n",
      "(eval) Reallocate neighbors list at step 6\n",
      "(eval) From (2, 8233) to (2, 8678)\n",
      "(eval) Reallocate neighbors list at step 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uppili11/.local/lib/python3.10/site-packages/jax/_src/ops/scatter.py:94: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(eval) From (2, 8678) to (2, 8936)\n",
      "(eval) Reallocate neighbors list at step 16\n",
      "(eval) From (2, 8936) to (2, 9191)\n",
      "{'val/loss': 0.0005722186507974004, 'val/mse1': 1.4546645693945957e-05, 'val/mse10': 0.00027800085150634073, 'val/mse5': 0.00013646225000015484, 'val/stdloss': 0.0, 'val/stdmse1': 0.0, 'val/stdmse10': 0.0, 'val/stdmse5': 0.0}\n"
     ]
    }
   ],
   "source": [
    "trainer = lagrangebench.Trainer(\n",
    "    model=gns,\n",
    "    case=ht2d_case,\n",
    "    data_train=ht2d_train,\n",
    "    data_valid=ht2d_valid,\n",
    "    pushforward=pf_config,\n",
    "    noise_std=noise_std,\n",
    "    metrics=[\"mse\"],\n",
    "    n_rollout_steps=20,\n",
    "    eval_n_trajs=1,\n",
    "    lr_start=5e-4,\n",
    "    log_steps=10,\n",
    "    eval_steps=50,\n",
    "    batch_size_infer=1,\n",
    ")\n",
    "\n",
    "params, state, _ = trainer(step_max=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
